{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Problem 1 [60 points] Lyapunov analysis for unforced and forced systems",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## (a) [15 + 15 = 30 points] Asymptotic stability for the unforced system\n\n(i) Consider the nonlinear system\n$$\\dot{x}_{1} = x_{2}, \\qquad \\dot{x}_{2} = -h_{1}(x_1) - h_2(x_2),$$\nwhere for $i=1,2$, the functions $h_{i}(\\cdot)$ are locally Lipschitz, $h_{i}(0)=0$ and $yh_{i}(y) > 0 \\;\\forall\\:y\\in(-a,a)$ for some nonzero real constant $a$. Clearly, the origin is a fixed point but there may be more fixed points depending on the nonlinear functions $h_{i}(\\cdot)$. **Prove that** the origin is AS.\n\nTo do this, motivated by the pendulum example in Lec. 3, p. 13-14 and Lec. 4, p. 1-2, consider the Lyapunov function $V(x_1,x_2) = \\int_{0}^{x_1}h_1(y)\\:{\\rm{d}}y + \\frac{1}{2}x_2^2$. This Lyapunov function can be thought of as a generalized energy: the intergal term is a generalized potential energy and the second summand is a generalized kinetic energy. You may need to use the LaSalle invariance.\n\n(ii) Let us consider a specific instance of the above given by\n$$\\dot{x}_{1} = x_{2}, \\qquad \\dot{x}_{2} = -\\alpha x_1^3 - \\beta x_2, \\qquad \\alpha,\\beta>0.$$\n**Prove that** the origin for this system is in fact GAS.\n\n## Solution for Prob 1(a):\n\n(i) Consider the domain $\\mathcal{D}:=\\{(x_1,x_2)\\in(-a,a)^{2}\\subset\\mathbb{R}^{2}\\}$. Then, the given $V$ is positive definite over $\\mathcal{D}$. Also, $\\dot{V} = -x_2 h_{2}(x_2) \\leq 0$. To apply LaSalle invariance, notice that $\\dot{V}=0\\:\\Rightarrow\\:x_2h_{2}(x_2)=0\\:\\Rightarrow\\: x_2=0$ since $-a <x_2 < a$. Therefore,\n$$\\{(x_1,x_2)\\in\\mathcal{D} \\mid \\dot{V}=0\\} = \\{(x_1,x_2)\\in\\mathcal{D} \\mid x_2=0\\}.$$\nBut $x_2(t)\\equiv 0\\:\\Rightarrow\\:\\dot{x}_2(t)\\equiv 0\\:\\Rightarrow\\:h_1(x_1(t))\\equiv 0\\:\\Rightarrow\\:x_1(t)\\equiv 0$. Therefore, the only solution that can stay identically in $\\{(x_1,x_2)\\in\\mathcal{D} \\mid \\dot{V}=0\\}$ is the trvial solution $(x_1,x_2)=(0,0)$. Therefore, by LaSalle invariance theorem, the origin is AS.\n\n(ii) In this case, $(0,0)$ is in fact the unique fixed point. Furthermore, we have $h_1(x_1)=\\alpha x_1^3$ and $h_2(x_2)=\\beta x_2$, which satisfy $h_{i}(0)=0$ and $yh_{i}(y) > 0 \\;\\forall\\:y\\in(-\\infty,\\infty)$ for $i\\in\\{1,2\\}$. In addition, the Lyapunov function\n$$V(x_1,x_2) = \\int_{0}^{x_1}h_1(y)\\:{\\rm{d}}y + \\frac{1}{2}x_2^2 = \\frac{1}{4}\\alpha x_{1}^{4} + \\frac{1}{2}x_2^2$$\nis radially unbounded since it goes to $+\\infty$ as $\\|x\\|_{2}\\rightarrow \\infty$. Because $a=\\infty$ in this case, the LaSalle invariance argument in part (i) applies to the domain $\\mathbb{R}^{2}$. Thus, by Barbashin-Krasovskii theorem, the origin is GAS.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## (b) [30 points] Finite gain $\\mathcal{L}_{2}$ stability for the forced system\n\nNow consider the forced system in input-output form given by\n$$\\dot{x}_{1} = x_{2}, \\qquad \\dot{x}_{2} = -\\alpha x_1^3 - \\beta x_2 + u, \\qquad \\alpha,\\beta>0, \\qquad y=x_2.$$\n\nUse Lec. 10, p. 1-2 to **prove that** the above system is finite gain $\\mathcal{L}_2$ stable **by deriving an upper bound on $\\mathcal{L}_2$ gain in terms of parameters $\\alpha,\\beta$**. \n\n(**Hint:** to use the Hamilton-Jacobi inequality theorem in Lec. 10, p. 1-2, choose the function $V$ to be a positive scaling of the Lyapunov function in part (a). This will lead to an inequality involving the gain upper bound $\\gamma$, the scaling and the parameters. Requiring $\\gamma$ to be smallest will yield the optimal scaling.)\n\n## Solution for Prob 1(b):\n\nFollowing the hint, let the candidate satisfying the Hamilton-Jacobi inequality be $V = c\\left(\\frac{1}{4}\\alpha x_{1}^{4} + \\frac{1}{2}x_2^2\\right)$ for some constant $c>0$. We have\n$$f = \\begin{pmatrix}\nx_2\\\\\n-\\alpha x_1^{3} - \\beta x_2\n\\end{pmatrix}, \\quad g = \\begin{pmatrix}\n0\\\\\n1\n\\end{pmatrix}, \\quad h = x_2, \\quad \\nabla_x V = \\begin{pmatrix}\nc\\alpha x_1^3\\\\\nc x_2\n\\end{pmatrix}.$$\nFrom Lec. 10, p. 2, the Hamilton-Jacobi inequality becomes:\n$$c\\alpha x_1^{3}x_2 + cx_2\\left(-\\alpha x_1^{3} - \\beta x_2\\right) + \\frac{c^2 x_2^2}{2\\gamma^2} + \\frac{1}{2}x_2^2 = \\left(-c\\beta+ \\frac{c^2}{2\\gamma^2}+ \\frac{1}{2}\\right)x_2^2 \\leq 0.$$\nSo we need to choose $c>0$ and $\\gamma>0$ such that $\\left(-c\\beta+ \\frac{c^2}{2\\gamma^2}+ \\frac{1}{2}\\right) \\leq 0$, which we rearrange as\n$$\\gamma^{2} \\geq \\frac{c^2}{2 c \\beta - 1}.$$\nBecause we are interested in the smallest possible $\\gamma$, we seek $c$ to minimize the RHS of the above inequality. This is achieved by $c=1/\\beta$ yielding the minimum RHS value $1/\\beta^2$. Therefore, the smallest $\\gamma>0$ that makes the system finite gain $\\mathcal{L}_2$ stable is the positive root of $\\gamma^2 = 1/\\beta^2$, i.e., $\\gamma = 1/\\beta$. The corresponding $\\mathcal{L}_2$ gain is $\\leq 1/\\beta$.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Problem 2 [40 points] $\\mathcal{L}_{p}$ gain for composition\n\nIn Lec. 10, p. 3-4, we stated that the finite gain $\\mathcal{L}_{p}$ stability is preserved under series and parrallel compositions of the subsystems. **Prove the same by deriving $\\mathcal{L}_{p}$ gain upper bound for the overall system in terms of the $\\mathcal{L}_{p}$ gain upper bounds for the subsystems**.\n\n## Solution for Prob. 2:\n**Proof for series composition:** Consider two subsystems in series composition wherein for $i\\in\\{1,2\\}$, the subsystem $i$ has input $u_i$ with output $y_i$ satisfying $\\|y_i\\|_{\\mathcal{L}_p} \\leq \\gamma_i \\|u_i\\|_{\\mathcal{L}_p}$. For series composition, we have $y_1=u_2$. Thus,\n$$\\|y_2\\|_{\\mathcal{L}_p} \\leq \\gamma_2 \\|u_2\\|_{\\mathcal{L}_p} = \\gamma_2 \\|y_1\\|_{\\mathcal{L}_p} \\leq \\gamma_1\\gamma_2\\|u_1\\|_{\\mathcal{L}_p}.$$\nFor the overall system, $u=u_1$ and $y=y_2$, and therefore, we get $\\|y\\|_{\\mathcal{L}_p} \\leq \\gamma \\|u\\|_{\\mathcal{L}_p}$ where $\\gamma:=\\gamma_1\\gamma_2$. Clearly, the proof generalizes for the series composition of more than two subsystems with $\\gamma = \\prod_i \\gamma_i$.\n\n**Proof for parallel composition:** Consider two subsystems in parallel composition wherein for $i\\in\\{1,2\\}$, the subsystem $i$ has input $u_i$ with output $y_i$ satisfying $\\|y_i\\|_{\\mathcal{L}_p} \\leq \\gamma_i \\|u_i\\|_{\\mathcal{L}_p}$. For parallel composition, we have $u_1=u_2$. For the overall system, $u=u_1=u_2$ and $y=y_1+y_2$. Thus,\n$$\\|y\\|_{\\mathcal{L}_p} = \\|y_1 + y_2\\|_{\\mathcal{L}_p} \\leq \\|y_1\\|_{\\mathcal{L}_p} + \\|y_2\\|_{\\mathcal{L}_p} \\leq  \\gamma_1\\|u_1\\|_{\\mathcal{L}_p} + \\gamma_2\\|u_2\\|_{\\mathcal{L}_p} =\\left(\\gamma_1+\\gamma_2\\right)\\|u\\|_{\\mathcal{L}_p}.$$\nTherefore, we get $\\|y\\|_{\\mathcal{L}_p} \\leq \\gamma \\|u\\|_{\\mathcal{L}_p}$ where $\\gamma:=\\gamma_1 + \\gamma_2$. Clearly, the proof generalizes for the parallel composition of more than two subsystems with $\\gamma = \\sum_i \\gamma_i$.",
      "metadata": {}
    }
  ]
}