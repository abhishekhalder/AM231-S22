{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Pyolite",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# Problem 1. [2 x 4 = 8 points] Activation Function and Sector Nonlinearity\n\nIn Lec. 11, p. 14-16, we introduced sector nonlinearity. In this exercise, we examine some concrete examples/non-examples.\n\n**Explain** which of the following commonly used neural network activation functions $\\sigma:\\mathbb{R}^{m}\\mapsto\\mathbb{R}^{m}$, are sector bounded and which are not? If any of these are sector-bounded then **derive** the corresponding sectors $[\\alpha,\\beta]$ as in Lec. 11, p. 15-16.\n\n(a) ReLU activation $\\sigma(x) = \\max\\{0_{m\\times 1},x\\}$ where $x\\in\\mathbb{R}^{m}$ and $\\max\\{\\cdot,\\cdot\\}$ is elementwise.\n\n(b) Leaky ReLU activation $\\sigma(x) = \\max\\{a x,x\\}$ where $x\\in\\mathbb{R}^{m}$, $a>0$, and $\\max\\{\\cdot,\\cdot\\}$ is elementwise.\n\n(c) Sigmoid activation $\\sigma(x) = \\exp(x)\\oslash\\left(\\boldsymbol{1} + \\exp(x)\\right)$ where $x\\in\\mathbb{R}^{m}$, $\\boldsymbol{1}$ is all-ones column vector, $\\oslash$ denotes elementwise division, and $\\exp(\\cdot)$ is elementwise. \n\n(d) Softmax activation $\\sigma(x) = \\dfrac{\\exp(x)}{\\boldsymbol{1}^{\\top}\\exp(x)}$ where $x\\in\\mathbb{R}^{m}$, $\\boldsymbol{1}$ is all-ones column vector, and $\\exp(\\cdot)$ is elementwise. ",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Solution for Prob. 1.\n\n(a) Since $0_{m\\times 1}\\leq \\max\\{0_{m\\times 1},x\\} \\leq x$, hence ReLU activation is sector bounded in $[\\alpha,\\beta] = [0,1]$.\n\n(b) If $a\\geq 1$ then $x\\leq \\max\\{a x,x\\} \\leq ax$. If $1>a>0$ then $ax\\leq \\max\\{a x,x\\} \\leq x$. Thus, leaky ReLU activation is sector bounded in $[\\alpha,\\beta]=[\\min(a,1),\\max(a,1)]$.\n\n(c) The sigmoid is not sector bounded but the shifted sigmoid $\\sigma(x)-\\sigma(0) = \\sigma(x) - (1/2)\\boldsymbol{1}$ is sector bounded in $[\\alpha,\\beta] = [0,1]$.\n\n(d) The softmax is not sector bounded but the shifted softmax $\\sigma(x)-\\sigma(0) = \\sigma(x) - (1/m)\\boldsymbol{1}$ is sector bounded in $[\\alpha,\\beta] = [0,1]$.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Problem 2. [50 points] Feedback Stabilization \n\nConsider the scalar control system $\\dot{x}=-x^{3} + u$. We want to design (static) state feedback control $u=u(x)$ such that origin of the closed-loop system is GAS. We will design multiple stabilizing controllers for this system, and compare their performance.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "(a) **[5 points]** Design a **feedback linearizing controller** $u_{\\rm{FL}}(x)$ by applying \"cancel the nonlinearity and get a stable linear closed-loop system\" idea.\n\n## Solution for Prob. 2(a)\nMotivated by the \"cancel the nonlinearity and get a stable linear closed-loop system\" idea, we take $u_{\\rm{FL}}(x) = x^3 - x$ (more generally, can take $u_{\\rm{FL}}(x) = x^3 - kx$ for some $k>0$). This results in a closed-loop system $\\dot{x} = -x$ , which makes the origin GAS.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "(b) **[5 points]** Prove that a **linear feedback controller** $u_{\\rm{L}}(x)=âˆ’x$ also makes the origin of the closed-loop system GAS. You will need to use the Barbashin-Krtasovskii theorem.\n\n## Solution fot Prob. 2(b)\nFor $u_{\\rm{L}}(x) = âˆ’x$, we get the closed-loop system $\\dot{x} = âˆ’x^{3} âˆ’ x$. Taking $V(x)=\\frac{1}{2}x^2$ (positive definite function, radially unbounded), we get $\\dot{V}=-x^2 - x^4 <0$ for all $x\\neq 0$. By the Barbashin-Krasovskii theorem, this guarantees that the origin is GAS.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "(c) **[5 + 5 = 10 points]** **Give two reasons** why the controller $u_{\\rm{L}}(x)$ in part (b) is a better controller than $u_\\rm{FL}(x)$ in part (a). (**Hint:** think rate-of-convergence of the closed-loop system, and magnitude of control signal for large $x$. For the latter, you may find it insightful to plot $|u|$ as function of $x$.)\n\n## Solution for Prob. 2(c)\nThe controller in part (b) entails faster rate of convergence than the controller in part (a). One way to see this is to solve the scalar closed-loop systems:\n$$x_{\\rm{FL}}(t) = x_{0}e^{-t}, \\qquad x_{\\rm{L}}(t) = \\pm x_{0}\\left((1+x_{0}^{2})\\left(e^{2t} - \\frac{x_{0}^{2}}{1 + x_{0}^{2}}\\right)\\right)^{-\\frac{1}{2}},$$\nand notice that the latter decays faster than $e^{-t}$.\n\nSecond reason to prefer the controller in part (b) over the controller in part (a) is that for large $|x|$ (far from origin), larger control effort is needed for $u_{\\rm{FL}}(x)$ than $u_{\\rm{L}}(x)$. This is illustrated in the following plot.\n<img src=\"xversusabsu.png\">",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "(d) **[5 points]** The answer in part (c) tells us that it is better not to kill \"friendly nonlinearity\". Consider another design idea: **doing nothing controller**, i.e., $u_0(x)\\equiv 0$ for all $x\\in\\mathbb{R}$. Prove that $u_0(x)$ also makes the origin GAS.\n\n## Solution for Prob. 2(d)\nThe controller $u_0(x)\\equiv 0$ for all $x\\in\\mathbb{R}$, results in the closed-loop dynamics $\\dot{x}=-x^3$ , which again by taking $V(x)=\\frac{1}{2}x^2$, yields $\\dot{V}=-x^4 <0$ for all $x \\neq 0$, thereby establishing GAS for the origin via the Barbashin-Krasovskii theorem.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "(e) **[5 + 5 = 10 points]** **Give one advantage and one disadvantage** of $u_0(x)$ compared to $u_{\\rm{L}}(x)$. Again think in terms of the hint in part (c).\n\n## Solution for Prob. 2(e)\nAn **advantage** of $u_0(x)$ is that the control effort is always zero (smaller than any other control strategy). A **disadvantage** of $u_0(x)$ is that for small $|x|$ (near the origin), the rate of convergence is slower than that resulting from $u_{\\rm{L}}(x)$. This can be seen by solving the closed-loop system for $u_0(x)$ as $x(t) = \\pm x_{0}/\\sqrt{1+2tx_{0}^{2}}$ and comparing with $x_{\\rm{L}}(t)$ above. We can also compare $|\\dot{x}|$ for small $|x|$ to get the same conclusion.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "(f) **[5 points]** Design another globally asymptotically stabilizing controller $u_{\\rm{S}}(x)$ using **Sontagâ€™s formula** in Lec. 13. For this purpose, you need to use a CLF: use what comes to your mind without much thought.\n\n## Solution for Prob. 2(f)\nWe take $V(x)=\\frac{1}{2}x^{2}$ as the CLF, and use Sontagâ€™s formula to get the stabilizing controller\n$$u_{\\rm{S}}(x) = \\frac{x^{4} - \\sqrt{x^{8} + x^{4}}}{x} = x^{3} - x\\sqrt{x^{4} + 1}, \\quad\\text{for}\\quad x\\neq 0.$$\nNotice that the formula automatically captures $u_{\\rm{S}}(x)=0$ for $x=0$.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "(g) **[5 + 5 = 10 points]** From your answer in part (f), **argue that** near $x=0$, we have $u_{\\rm{S}}(x)\\approx u_{\\rm{L}}(x)$; and for $|x|\\rightarrow\\infty$, we have $u_{\\rm{S}}(x)\\approx u_{0}(x)$, and therefore, $u_{\\rm{S}}(x)$ outperforms all the previous controllers.\n\nIn a single figure, **plot all the four controllers** as functions of $x$.\n\n## Solution for Prob. 2(g)\nExpanding $u_{\\rm{S}}(x)$ in Taylor series about $x=0$ yields\n$$-x + x^{3} -\\frac{x^{5}}{2} + \\frac{x^{9}}{8} + O\\left(x^{11}\\right).$$\nTherefore, up to first order, $u_{\\rm{S}}(x) \\approx u_{\\rm{L}}(x)$ near $x=0$.\n\nNext, expanding $u_{\\rm{S}}(1/x)$ in Taylor series about $x=0$ (equivalent to expanding $u_{\\rm{S}}(1/x)$ about $|x|=\\infty$), we get\n$$-\\frac{1}{2x} + \\frac{1}{8x^{5}} - \\frac{1}{16x^{9}} + O\\left(\\frac{1}{x^{11}}\\right),$$\nwhich tells us that $u_{\\rm{S}}(x) \\approx u_{0}(x)$ as $|x|\\rightarrow\\infty$, hence the claim.\n\nThe following plot compares all the four feedback controllers.\n<img src=\"AllFourFeedbackControllers.png\">",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# Problem 3. [42 points] Backstepping\n\nConsider the following 3 state control system which is a modification of the worked out example in Lec. 13, p. 14-16, with an additional integrator at the input side:\n\\begin{array}{l}\n\\dot{x}_{1}=x_{1}^{2}-x_{1}^{3}+x_{2}, \\\\\n\\dot{x}_{2}=x_{3}, \\\\\n\\dot{x}_{3}=u.\n\\end{array}",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## (a) [20 points] Controller synthesis\n**Design** an integrator backstepping controller to make the origin GAS. In other words, find the feedback $u(x_1,x_2,x_3)$ and the overall Lyapunov certificate $V(x_1,x_2,x_3)$.\n\n## Solution for Prob. 3(a)\nFrom the worked out backstepping example in Lec. 13, p 14-16, we know that the second order system\n\\begin{align*}\n\\begin{array}{l}\n\\dot{x}_{1}=x_{1}^{2}-x_{1}^{3}+x_{2}, \\\\\n\\dot{x}_{2}=x_{3},\n\\end{array}\n\\end{align*}\nwith $x_3$ as input, has global stabilizing controller\n$$x_{3} = -x_{1}-\\left(1+2x_{1}\\right)\\left(x_{1}^{2}-x_{1}^{3}+x_{2}\\right) -\\left(x_{2} + x_{1} + x_{1}^{2}\\right) =: \\phi\\left(x_{1},x_{2}\\right),$$\nand $V(x_1,x_2) = \\frac{1}{2}x_{1}^{2} + \\frac{1}{2}\\left(x_{2} + x_{1} + x_{1}^{2}\\right)^{2}$ is the corresponding Lyapunov function.\n\nTo backstep further, we introduce the change-of-variable $z_{3} := x_{3} - \\phi(x_{1},x_{2})$, and obtain\n\\begin{align*}\n\\begin{array}{l}\n\\dot{x}_{1}=x_{1}^{2}-x_{1}^{3}+x_{2}, \\\\\n\\dot{x}_{2}= \\phi(x_1,x_2) + z_{3},\\\\\n\\dot{z}_{3} = u - \\frac{\\partial\\phi}{\\partial x_{1}}\\left(x_{1}^{2}-x_{1}^{3}+x_{2}\\right) - \\frac{\\partial\\phi}{\\partial x_{2}}\\left(\\phi + z_{3}\\right).\n\\end{array}\n\\end{align*}\nLetting $V_{c}:=V(x_1,x_2) + \\frac{1}{2}z_{3}^{2}$, we get\n\\begin{aligned} \\dot{V}_{c} &=\\frac{\\partial V}{\\partial x_{1}}\\left(x_{1}^{2}-x_{1}^{3}+x_{2}\\right)+\\frac{\\partial V}{\\partial x_{2}}\\left(\\phi+z_{3}\\right)+z_{3}\\left(u-\\frac{\\partial \\phi}{\\partial x_{1}}\\left(x_{1}^{2}-x_{1}^{3}+x_{2}\\right)-\\frac{\\partial \\phi}{\\partial x_{2}}\\left(\\phi+z_{3}\\right)\\right) \\\\ &=-x_{1}^{2}-x_{1}^{4}-\\left(x_{2}+x_{1}+x_{1}^{2}\\right)^{2}+z_{3}\\left(\\frac{\\partial V}{\\partial x_{2}}+u-\\frac{\\partial \\phi}{\\partial x_{1}}\\left(x_{1}^{2}-x_{1}^{3}+x_{2}\\right)-\\frac{\\partial \\phi}{\\partial x_{2}}\\left(\\phi+z_{3}\\right)\\right), \\end{aligned}\nand therefore, we can set\n$$u(x_{1},x_{2},x_{3}) = -\\frac{\\partial V}{\\partial x_{2}} + \\frac{\\partial\\phi}{\\partial x_{1}} \\left(x_{1}^{2}-x_{1}^{3}+x_{2}\\right) + \\frac{\\partial\\phi}{\\partial x_{2}}\\left(\\phi + z_{3}\\right) - z_{3},$$\nresulting in\n$$\\dot{V}_{c}=-x_{1}^{2}-x_{1}^{4}-\\left(x_{2}+x_{1}+x_{1}^{2}\\right)^{2}-z_{3}^{2} \\leq-\\{\\underbrace{x_{1}^{2}+\\left(x_{2}+x_{1}+x_{1}^{2}\\right)^{2}+z_{3}^{2}}_{\\text {positive definite function }}\\}.$$\nThus, the controller $u(x_1,x_2,x_3)$ above makes the origin GAS, and the associated Lyapunov certificate is\n\\begin{aligned} V_{c}\\left(x_{1}, x_{2}, x_{3}\\right) &=V\\left(x_{1}, x_{2}\\right)+\\frac{1}{2}\\left(x_{3}-\\phi\\left(x_{1}, x_{2}\\right)\\right)^{2} \\\\ &=\\frac{1}{2} x_{1}^{2}+\\frac{1}{2}\\left(x_{2}+x_{1}+x_{1}^{2}\\right)^{2}+\\frac{1}{2}\\left[x_{3}+x_{1}+\\left(1+2 x_{1}\\right)\\left(x_{1}^{2}-x_{1}^{3}+x_{2}\\right)+\\left(x_{2}+x_{1}+x_{1}^{2}\\right)\\right]^{2}.\\end{aligned}",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "## (b) [22 points] Numerical simulation\n\nUse your answer in part (a) to write a MATLAB function $\\texttt{ğ™±ğšŠğšŒğš”ğšœğšğšğš™ğš™ğš’ğš—ğšğ™²ğš•ğš˜ğšœğšğšğ™»ğš˜ğš˜ğš™.ğš–}$ that can be called by the supplied executable $\\texttt{ğ™±ğšŠğšŒğš”ğšœğšğšğš™ğš™ğš’ğš—ğš.ğš–}$ in CANVAS Files section. Submit the two plots generated by $\\texttt{ğ™±ğšŠğšŒğš”ğšœğšğšğš™ğš™ğš’ğš—ğš.ğš–}$: \n\n(i) a phase portrait of the closed loop dynamics for 10 randomly generated initial conditions, \n\n(ii) a representative time series plot for a specific controlled trajectory.\n\nThe plot commands are already there in $\\texttt{ğ™±ğšŠğšŒğš”ğšœğšğšğš™ğš™ğš’ğš—ğš.ğš–}$. So your job is to correctly implement the function $\\texttt{ğ™±ğšŠğšŒğš”ğšœğšğšğš™ğš™ğš’ğš—ğšğ™²ğš•ğš˜ğšœğšğšğ™»ğš˜ğš˜ğš™.ğš–}$.\n\n## Solution for Prob. 3(b)\nSee the MATLAB function $\\texttt{ğ™±ğšŠğšŒğš”ğšœğšğšğš™ğš™ğš’ğš—ğšğ™²ğš•ğš˜ğšœğšğšğ™»ğš˜ğš˜ğš™.ğš–}$ inside CANVAS Files section. Two sample plots generated by the same are shown below.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {},
      "execution_count": null,
      "outputs": []
    }
  ]
}